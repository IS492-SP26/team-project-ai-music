Proposal:
We’re building an AI Songwriting Copilot for non-musicians because a lot of people want to write songs but genuinely don’t know how to begin. With TikTok, YouTube, and short-form content becoming so common, songwriting is no longer something limited to trained musicians. Casual creators, students, and hobbyists often have a vibe, a story, or even just a catchy line in their head, but they get stuck almost immediately. They might not understand chord progressions, they might not know how songs are structured, and even writing lyrics that feel cohesive can be intimidating. The barrier is not creativity, it is knowing how to translate an idea into a structured song.
Existing AI music tools tend to fall into two extremes. Some systems generate fully produced songs from a single prompt, which feels impressive but removes most of the user’s control. You get a finished product, but you cannot easily edit specific lines, adjust the structure, or understand why the song works. On the other side, text-based AI tools can help write lyrics, but they usually ignore the musical side of things and do not guide users through the process. Research on co-creative AI systems emphasizes that users benefit most when the AI acts as a collaborator rather than a replacement. Right now, there is a gap between push-button song generation and actual guided songwriting support.
Our approach is to design a structured, chat-based copilot that breaks songwriting into manageable steps. A user can start with something simple, like a mood or short paragraph. The system then proposes a song blueprint with sections and an emotional arc. From there, it generates lyrics that match the chosen tone and suggests beginner-friendly chord progressions in a selected key. The important part is iteration. Users can ask the system to rewrite only the chorus, simplify the chords, keep specific lines, or adjust the rhyme scheme. Instead of replacing the user’s creativity, the tool supports it and keeps the human in control. This makes it more aligned with human-AI collaboration principles and improves on prior systems that either over-automate or under-structure the process.
For Checkpoint 2, we plan to validate this idea through structured prompting experiments using existing LLM APIs. We will create a set of representative songwriting scenarios across different moods and genres, then test prompt templates for blueprint generation, lyric constraints, chord consistency, and targeted rewrites. We will evaluate outputs based on coherence across sections, adherence to user constraints, originality, and how well the system preserves user-specified edits. We also plan to gather quick feedback from classmates to see whether the workflow feels intuitive and whether users feel ownership over the song.
There are several risks we are aware of. The model could unintentionally echo copyrighted lyrics, generate biased or inappropriate content, or suggest musically inconsistent chords. Users may also share personal stories in prompts, which raises privacy concerns. To mitigate these issues, we will instruct the model to generate original content, avoid prompts that request imitation of specific songs, default to a clean content mode, add simple checks for key and chord consistency, and avoid storing user inputs beyond the session. Overall, our goal is not to build a full music generation model, but to design a collaborative system that lowers the barrier to songwriting while keeping creativity human-centered.

