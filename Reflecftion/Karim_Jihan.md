**Research Review 1**

**The Ghost in the Keys: A Disklavier Demo for Human-AI Musical Co-Creativity**

Citation

Bradshaw, L., Spangher, A., Biderman, S., & Colton, S. (2025). The Ghost in the Keys: A Disklavier Demo for Human-AI Musical Co-Creativity. NeurIPS 2025 (Creative AI Track).
https://arxiv.org/abs/2511.01663

**Summary**

This paper explores how to make AI music collaboration feel truly interactive rather than delayed or disconnected. The authors introduce Aria-Duet, a system that allows a pianist to perform live with an AI model using a Yamaha Disklavier. Instead of relying on text prompts or offline generation, the system enables real-time, turn-based musical dialogue with low latency. The model is trained on large-scale MIDI piano data and is engineered to respond quickly while preserving harmonic structure, phrasing, and stylistic coherence. The results show that embodied, live collaboration between a human and AI can feel musically meaningful rather than robotic.

**Key Insights**

- Real-time responsiveness is just as important as model quality in creative AI systems.

- Musical coherence involves harmony, phrasing, structure, and expressive timingâ€”not just correct notes.

- Physical embodiment (playing on an acoustic instrument) changes how AI collaboration is experienced.

**Limitations / Risks**

- Evaluation is largely qualitative and demo-based rather than grounded in controlled user studies.

- AI music tools may influence creative diversity or shift collaborative dynamics between musicians.

**Project Inspiration**

Prioritize real-time interaction and user agency in my project design, possibly incorporating structured turn-taking or low-latency feedback mechanisms.

**Research Review 2**

**An Agent-Based Framework for Automated Higher-Voice Harmony Generation**

Citation

Yin, H., Zhang, R., Chen, Z., & Li, Y. (2025). An Agent-Based Framework for Automated Higher-Voice Harmony Generation. arXiv preprint arXiv:2508.08973.
https://arxiv.org/abs/2508.08973

**Summary**

This paper focuses on the challenge of generating higher-voice harmonies for a given melody in a musically coherent way. Instead of using a single end-to-end model, the authors propose an agent-based system where different components handle specific musical tasks like chord reasoning, melody harmonization, rhythm alignment, and audio synthesis. These specialized "agents" work together to produce harmonies that follow music theory principles and maintain stylistic consistency. The framework is evaluated using objective metrics and listening-based assessments, showing improvements in harmonic accuracy and perceived musical naturalness. The study demonstrates that modular AI systems can better reflect the layered structure of music composition.

**Key Insights**

- Breaking music generation into specialized roles mirrors how human composers think about harmony and structure.

- Voice leading and harmonic correctness significantly affect perceived musical quality.

- Modular systems offer greater transparency and control than monolithic generative models.

**Limitations / Risks**

- Multi-agent coordination increases system complexity and potential error propagation.

- Technical harmonic correctness does not fully capture creativity or listener preference.

**Project Inspiration**

Structure my project using modular components (e.g., planning, generation, refinement) to improve control, interpretability, and musical coherence.

